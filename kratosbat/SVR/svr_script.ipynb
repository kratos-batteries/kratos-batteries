{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbasecondaaedb3b0a6ce64122a565c132635c4aab",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X1 = pd.read_csv('../Data/DataForSVR/GC_PCA.csv',index_col=0)\n",
    "    y1 = pd.read_csv('../Data/NEWTrainingData_StandardScaler.csv',index_col=0).loc[:, ['Gravimetric Capacity (units)']]\n",
    "    X2 = pd.read_csv('../Data/DataForSVR/VC_PCA.csv',index_col=0)\n",
    "    y2 = pd.read_csv('../Data/NEWTrainingData_StandardScaler.csv',index_col=0).loc[:, ['Volumetric Capacity']]\n",
    "    X3 = pd.read_csv('../Data/DataForSVR/MDV_PCA.csv',index_col=0)\n",
    "    y3 = pd.read_csv('../Data/NEWTrainingData_StandardScaler.csv',index_col=0).loc[:, ['Max Delta Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train,X1_test, y1_train, y1_test =train_test_split(X1,y1,test_size=0.2, random_state=123)\n",
    "X2_train,X2_test, y2_train, y2_test =train_test_split(X2,y2,test_size=0.2, random_state=123)\n",
    "X3_train,X3_test, y3_train, y3_test =train_test_split(X3,y3,test_size=0.2, random_state=123)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.33136629285159\n0.7047146415804826\n"
    }
   ],
   "source": [
    "    \n",
    "    svr = SVR(kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=16.0, epsilon=0.1, \\\n",
    "              shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
    "    svr.fit(X1_train, y1_train)\n",
    "    joblib.dump(svr, 'svr_GC.pkl')\n",
    "    y1_pred=svr.predict(X1_test)\n",
    "    print(mean_squared_error(y1_test, y1_pred)) \n",
    "    print(r2_score(y1_test,y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.3019634215812373\n0.7280673360654664\n"
    }
   ],
   "source": [
    "    svr = SVR(kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=8.0, epsilon=0.1, \\\n",
    "              shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
    "    svr.fit(X2_train, y2_train)\n",
    "    joblib.dump(svr, 'svr_CV.pkl') \n",
    "    y2_pred=svr.predict(X2_test)\n",
    "    print(mean_squared_error(y2_test, y2_pred)) \n",
    "    print(r2_score(y2_test,y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.013030072473806137\n0.8038315261297109\n"
    }
   ],
   "source": [
    "    svr = SVR(kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=4.8, epsilon=0.1, \\\n",
    "              shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
    "    svr.fit(X3_train, y3_train)\n",
    "    joblib.dump(svr, 'svr_MDV.pkl') \n",
    "    y3_pred=svr.predict(X3_test)\n",
    "    print(mean_squared_error(y3_test, y3_pred)) \n",
    "    print(r2_score(y3_test,y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.09270279792016779\n0.8932005971820075\n"
    }
   ],
   "source": [
    "\n",
    "    svr_cg = joblib.load('svr_GC.pkl')\n",
    "    svr_cv = joblib.load('svr_CV.pkl')\n",
    "    svr_mdv = joblib.load('svr_MDV.pkl')\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    kf.get_n_splits(X1, y1)   \n",
    "    list_mse=[]\n",
    "    list_R2=[]\n",
    "    for train_index, test_index in kf.split(X1, y1):\n",
    "        X1_train, X1_test = X1.iloc[train_index], X1.iloc[test_index]\n",
    "        y1_train, y1_test = y1.iloc[train_index], y1.iloc[test_index]\n",
    "        y1_pred = svr_cg.predict(X1_test)\n",
    "        list_mse.append(mean_squared_error(y1_test, y1_pred))\n",
    "        list_R2.append(r2_score(y1_test,y1_pred))\n",
    "    print(pd.Series(list_mse).mean())\n",
    "    print(pd.Series(list_R2).mean())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.09156795891580712\n0.8964330893514024\n"
    }
   ],
   "source": [
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    kf.get_n_splits(X2, y2)   \n",
    "    list_mse=[]\n",
    "    list_R2=[]\n",
    "    for train_index, test_index in kf.split(X2, y2):\n",
    "        X2_train, X2_test = X2.iloc[train_index], X2.iloc[test_index]\n",
    "        y2_train, y2_test = y2.iloc[train_index], y2.iloc[test_index]\n",
    "        y2_pred = svr_cv.predict(X2_test)\n",
    "        list_mse.append(mean_squared_error(y2_test, y2_pred))\n",
    "        list_R2.append(r2_score(y2_test,y2_pred))\n",
    "    print(pd.Series(list_mse).mean())\n",
    "    print(pd.Series(list_R2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.6260500969700062\n0.7966426044743085\n"
    }
   ],
   "source": [
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    kf.get_n_splits(X3, y3)   \n",
    "    list_mse=[]\n",
    "    list_R2=[]\n",
    "    for train_index, test_index in kf.split(X3, y3):\n",
    "        X3_train, X3_test = X3.iloc[train_index], X3.iloc[test_index]\n",
    "        y3_train, y3_test = y3.iloc[train_index], y3.iloc[test_index]\n",
    "        y3_pred = svr_mdv.predict(X3_test)\n",
    "        list_mse.append(mean_squared_error(y3_test, y3_pred))\n",
    "        list_R2.append(r2_score(y3_test,y3_pred))\n",
    "    print(pd.Series(list_mse).mean())\n",
    "    print(pd.Series(list_R2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,yactual,color='red',lw='3',label='actual')\n",
    "plt.plot(x,regr.predict(x.reshape(-1,1)),ls='--',label='fit')\n",
    "plt.legend(loc='lower right')"
   ]
  }
 ]
}